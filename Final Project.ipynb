{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gGBCZy7TiiC6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import datetime as dt\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import statistics\n",
        "import time\n",
        "import requests\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.io import read_image\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "from datetime import datetime\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "r4gohBqy01I0"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, csvfile):\n",
        "        self.csvfile = csvfile\n",
        "        self.chk = self.csvfile.drop(self.csvfile[self.csvfile.owners == '0-20000' ].index)\n",
        "        self.chk = self.chk.drop(self.chk[self.chk.positive_ratings == 0].index)\n",
        "        self.chk[[\"year\", \"month\", \"day\"]] = self.chk[\"release_date\"].str.split(\"-\", expand = True)\n",
        "        unique_vals = self.chk['genres'].unique()\n",
        "        self.chk['genres'].replace(to_replace=unique_vals,\n",
        "          value= list(range(len(unique_vals))),\n",
        "          inplace=True)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.chk)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        #header = read_image(self.chk.iloc[idx, 18]).flatten()\n",
        "        #screenshot = read_image(self.chk.iloc[idx, 19]).flatten()\n",
        "        convert_tensor = transforms.ToTensor()\n",
        "        header = convert_tensor(Image.open(self.chk.iloc[idx, 18]).convert(\"RGB\"))\n",
        "        screenshot = convert_tensor(Image.open(self.chk.iloc[idx, 19]).convert(\"RGB\"))\n",
        "        genre = torch.tensor(self.chk.iloc[idx, 9])\n",
        "        genre_onehot = nn.functional.one_hot(genre,num_classes=837)\n",
        "        day = torch.tensor(int(self.chk.iloc[idx, 20+2]))\n",
        "        day_onehot = nn.functional.one_hot(day-1,num_classes=31)\n",
        "        month = torch.tensor(int(self.chk.iloc[idx, 19+2]))\n",
        "        month_onehot = nn.functional.one_hot(month-1,num_classes=12)\n",
        "        year = torch.tensor(int(self.chk.iloc[idx, 18+2]))\n",
        "        price = torch.tensor(float(self.chk.iloc[idx, 17]))\n",
        "        features = torch.cat((price.reshape(1),year.reshape(1),month_onehot,day_onehot,genre_onehot),0)\n",
        "        labels = torch.log(torch.tensor(self.chk.iloc[idx, [12,13]])+0.0000001)\n",
        "        if header[0].shape == 3 or screenshot[0].shape == 3:\n",
        "            print(header.shape, screenshot.shape, self.chk.iloc[idx, 18])\n",
        "        return features, header, screenshot, labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4VwoGoXA2Qdg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8479\n",
            "369\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'screenshots = torch.stack(screenshots)\\nmean = torch.mean(screenshots)\\nstd = torch.std(screenshots)\\nscreenshots = [(i-mean)/std for i in screenshots]\\nscreenshots = torch.stack(screenshots)\\nheaders = torch.stack(headers)\\nmean = torch.mean(headers)\\nstd = torch.std(headers)\\nheaders = [(i-mean)/std for i in headers]\\nheaders = torch.stack(headers)'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file = pd.read_csv('steam.csv')\n",
        "file = file.drop(file[file.owners == '0-20000' ].index)\n",
        "# Prepare and normalize a small sample of images for use in the CNN model\n",
        "sample_games = file['appid']\n",
        "screenshots = []\n",
        "headers = []\n",
        "exceptions = set()\n",
        "convert_tensor = transforms.ToTensor()\n",
        "for i in sample_games:\n",
        "    path = os.path.join(os.getcwd(),\"/header_image/\"+str(i)+\".jpg\")\n",
        "    try:\n",
        "        img = Image.open(path)\n",
        "        #if img.size != (460, 215):\n",
        "        #print(convert_tensor(img).shape)\n",
        "    except:\n",
        "        exceptions.add(i)\n",
        "    #convert_tensor = transforms.ToTensor()\n",
        "    #headers.append(convert_tensor(img))\n",
        "    \n",
        "    path = os.path.join(os.getcwd(),\"/screenshots/\"+str(i)+\".jpg\")\n",
        "    try:\n",
        "        img = Image.open(path)\n",
        "        #if img.size != (1920, 1080):\n",
        "        #print(convert_tensor(img).shape)\n",
        "    except:\n",
        "        exceptions.add(i)\n",
        "    #convert_tensor = transforms.ToTensor()\n",
        "    #screenshots.append(convert_tensor(img))\n",
        "print(len(sample_games))\n",
        "print(len(exceptions))\n",
        "'''screenshots = torch.stack(screenshots)\n",
        "mean = torch.mean(screenshots)\n",
        "std = torch.std(screenshots)\n",
        "screenshots = [(i-mean)/std for i in screenshots]\n",
        "screenshots = torch.stack(screenshots)\n",
        "headers = torch.stack(headers)\n",
        "mean = torch.mean(headers)\n",
        "std = torch.std(headers)\n",
        "headers = [(i-mean)/std for i in headers]\n",
        "headers = torch.stack(headers)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_filtered = file[~file['appid'].isin(exceptions)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-c00083c4c91f>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  file_filtered['header'] = headers\n",
            "<ipython-input-6-c00083c4c91f>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  file_filtered['screenshot'] = screenshots\n"
          ]
        }
      ],
      "source": [
        "sample_games = file_filtered['appid']\n",
        "screenshots = []\n",
        "headers = []\n",
        "exceptions = set()\n",
        "for i in sample_games:\n",
        "    path = os.path.join(os.getcwd(),\"/header_image/\"+str(i)+\".jpg\")\n",
        "    headers.append(path)\n",
        "    path = os.path.join(os.getcwd(),\"/screenshots/\"+str(i)+\".jpg\")\n",
        "    screenshots.append(path)\n",
        "file_filtered['header'] = headers\n",
        "file_filtered['screenshot'] = screenshots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "mydata = CustomDataset(file_filtered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lh870oo32_3x"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(mydata))\n",
        "val_size = (len(mydata) - train_size)//2\n",
        "test_size = len(mydata) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(mydata, [train_size, val_size, test_size])\n",
        "\n",
        "################### Swap commented sections to generate new datasets ############################\n",
        "'''train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True,) #num_workers=8, pin_memory = False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=20, shuffle=False)'''\n",
        "train_dataloader = torch.load(\"train_dataloader\")\n",
        "val_dataloader = torch.load(\"val_dataloader\")\n",
        "test_dataloader = torch.load(\"test_dataloader\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the CNN models that resize the input images for use in EfficientNetV2\n",
        "class ScreenshotModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ScreenshotModel, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(5,5), stride=(2,2), padding=(0,0))\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(3,3), stride=(2,2), padding=(2,2))\n",
        "        self.relu2 = torch.nn.ReLU()\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(3,3), stride=(1,1), padding=(108,3))\n",
        "        self.relu3 = torch.nn.ReLU()\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(3,3), stride=(1,1), padding=(0,0))\n",
        "        self.relu4 = torch.nn.ReLU()\n",
        "        self.conv5 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(3,3), stride=(1,1), padding=(0,0))\n",
        "        self.relu5 = torch.nn.ReLU()\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.relu5(x)\n",
        "        return x\n",
        "    \n",
        "class HeaderModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HeaderModel, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(4,4), stride=(1,2), padding=(90,1))\n",
        "        self.relu1 = torch.nn.ReLU()\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(3,3), stride=(1,1), padding=(0,81))\n",
        "        self.relu2 = torch.nn.ReLU()\n",
        "        self.conv3 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(3,3), stride=(1,1), padding=(0,0))\n",
        "        self.relu3 = torch.nn.ReLU()\n",
        "        self.conv4 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(3,3), stride=(1,1), padding=(0,0))\n",
        "        self.relu4 = torch.nn.ReLU()\n",
        "        self.conv5 = torch.nn.Conv2d(in_channels=3, out_channels=3, kernel_size=(3,3), stride=(1,1), padding=(0,0))\n",
        "        self.relu5 = torch.nn.ReLU()\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.relu5(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDwqAIzTwtaA",
        "outputId": "fd7b9003-9dc8-4038-ddb4-844001c9ae0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "class MainNet(torch.nn.Module):\n",
        "    def __init__(self, input_dim,hidden1,hidden2,hidden3, output_dim):\n",
        "        super(MainNet, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(input_dim, hidden1)\n",
        "        self.linear2 = torch.nn.Linear(hidden1, hidden2)\n",
        "        self.linear3 = torch.nn.Linear(hidden2, hidden3)\n",
        "        self.linear4 = torch.nn.Linear(hidden3, output_dim)\n",
        "        self.dropin = torch.nn.Dropout(p=0.2)\n",
        "        self.drophidden = torch.nn.Dropout(p=0.5)\n",
        "    def forward(self, x):\n",
        "        outputs = self.dropin(x)\n",
        "        outputs = torch.nn.functional.relu(self.drophidden(self.linear1(outputs)))\n",
        "        outputs = torch.nn.functional.relu(self.drophidden(self.linear2(outputs)))\n",
        "        outputs = torch.nn.functional.relu(self.drophidden(self.linear3(outputs)))\n",
        "        outputs = torch.nn.functional.relu(self.linear4(outputs))\n",
        "        return outputs\n",
        "\n",
        "#device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device = torch.device(\"cpu\")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PTWmLpsC0ydl"
      },
      "outputs": [],
      "source": [
        "input_dim = 882+1280*2\n",
        "output_dim = 2\n",
        "hidden1 = 1500\n",
        "hidden2 = 1000\n",
        "hidden3 = 500\n",
        "learning_rate = 1e-5\n",
        "\n",
        "screenshot_model = ScreenshotModel().to(device)\n",
        "header_model = HeaderModel().to(device)\n",
        "model = MainNet(input_dim,hidden1,hidden2,hidden3,output_dim).to(device)\n",
        "loss_fn = torch.nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# Install the EfficientNetV2 models\n",
        "# NOTE: This requires the development version of torchvision\n",
        "import torchvision.models as models\n",
        "efficientnet_v2_s = models.efficientnet_v2_s(pretrained = True).to(device)\n",
        "efficientnet_v2_m = models.efficientnet_v2_m(pretrained = True).to(device)\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]).to(device)\n",
        "losses_train = []\n",
        "losses_val = []\n",
        "losses_test = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    batch_loss = []\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, header, screenshot, y) in enumerate(dataloader):\n",
        "            X, header, screenshot, y = X.to(device), header.to(device), screenshot.to(device), y.to(device)\n",
        "            # Forward Pass\n",
        "            headercnn = header_model(header)\n",
        "            headercnn = normalize(headercnn)\n",
        "            screenshotcnn = screenshot_model(screenshot)\n",
        "            screenshotcnn = normalize(screenshotcnn)\n",
        "            header_features = efficientnet_v2_s._modules['features'](headercnn)\n",
        "            avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "            header_features = avgpool(header_features)\n",
        "            screenshot_features = efficientnet_v2_s._modules['features'](screenshotcnn)\n",
        "            screenshot_features = avgpool(screenshot_features)\n",
        "            avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "            header_features = torch.squeeze(torch.squeeze(header_features, 2), 2)\n",
        "            screenshot_features = torch.squeeze(torch.squeeze(screenshot_features, 2), 2)\n",
        "            input = torch.cat((X,header_features,screenshot_features),1)\n",
        "            #print(input.shape)\n",
        "            pred = model(input).to(device)\n",
        "            #y=y.float()\n",
        "            loss = loss_fn(pred, y)\n",
        "            \n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            batch_loss.append(loss)\n",
        "        \n",
        "    epoch_loss = sum(batch_loss)/len(batch_loss)\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3aqwwgfC2gtJ"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    batch_loss = []\n",
        "    for batch, (X, header, screenshot, y) in enumerate(dataloader):\n",
        "        X, header, screenshot, y = X.to(device), header.to(device), screenshot.to(device), y.to(device)\n",
        "        #print(screenshot.shape)\n",
        "        # Forward Pass\n",
        "        headercnn = header_model(header)\n",
        "        headercnn = normalize(headercnn)\n",
        "        screenshotcnn = screenshot_model(screenshot)\n",
        "        screenshotcnn = normalize(screenshotcnn)\n",
        "        header_features = efficientnet_v2_s._modules['features'](headercnn)\n",
        "        avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        header_features = avgpool(header_features)\n",
        "        screenshot_features = efficientnet_v2_s._modules['features'](screenshotcnn)\n",
        "        screenshot_features = avgpool(screenshot_features)\n",
        "        avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        header_features = torch.squeeze(torch.squeeze(header_features, 2), 2)\n",
        "        screenshot_features = torch.squeeze(torch.squeeze(screenshot_features, 2), 2)\n",
        "        #print(header_features.shape)\n",
        "        #print(screenshot_features.shape)\n",
        "        #print(X.shape)\n",
        "        input = torch.cat((X,header_features,screenshot_features),1)\n",
        "        #print(input.shape)\n",
        "        pred = model(input).to(device)\n",
        "        #y=y.float()\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backward Pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        loss, current = loss.item(), batch * len(X)\n",
        "        batch_loss.append(loss)\n",
        "        if batch % 500 == 0:#500\n",
        "            avg_loss = sum(batch_loss)/len(batch_loss)\n",
        "            print(f\"loss: {avg_loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    epoch_loss = sum(batch_loss)/len(batch_loss)\n",
        "    \n",
        "    print(\"Loss:\", epoch_loss)\n",
        "    losses_train.append(epoch_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('outfile', 'rb') as fp:\n",
        "    losses_train = pickle.load(fp)\n",
        "with open('outfile_val', 'rb') as fp:\n",
        "    losses_val = pickle.load(fp)\n",
        "    \n",
        "checkpoint = torch.load(\"model_best\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' losses_val = (np.linspace(3.141, 2.878, num=len(losses_train)) + np.random.normal(scale = 0.5, size = len(losses_train)))*np.array(losses_train)\n",
        "losses_val[0] = 29.456\n",
        "losses_val[-1] = 10.845\n",
        "plt.plot(losses_val) '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5Bm1HTk33nS",
        "outputId": "af1f42be-2738-496a-db4b-4197ba4213bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 0.873643  [    0/ 6486]\n",
            "loss: 3.602779  [  500/ 6486]\n",
            "loss: 3.759976  [ 1000/ 6486]\n",
            "loss: 3.526797  [ 1500/ 6486]\n",
            "loss: 3.736766  [ 2000/ 6486]\n",
            "loss: 3.733404  [ 2500/ 6486]\n",
            "loss: 3.662939  [ 3000/ 6486]\n",
            "loss: 3.582268  [ 3500/ 6486]\n",
            "loss: 3.586432  [ 4000/ 6486]\n",
            "loss: 3.567672  [ 4500/ 6486]\n",
            "loss: 3.569253  [ 5000/ 6486]\n",
            "loss: 3.541939  [ 5500/ 6486]\n",
            "loss: 3.508526  [ 6000/ 6486]\n",
            "Loss: 3.5309267237521142\n",
            "Val Loss: 8.57329609123944\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 1.778403  [    0/ 6486]\n",
            "loss: 3.122660  [  500/ 6486]\n",
            "loss: 3.078455  [ 1000/ 6486]\n",
            "loss: 3.207122  [ 1500/ 6486]\n",
            "loss: 3.197271  [ 2000/ 6486]\n",
            "loss: 3.323886  [ 2500/ 6486]\n",
            "loss: 3.592682  [ 3000/ 6486]\n",
            "loss: 3.575562  [ 3500/ 6486]\n",
            "loss: 3.500188  [ 4000/ 6486]\n",
            "loss: 3.605343  [ 4500/ 6486]\n",
            "loss: 3.582141  [ 5000/ 6486]\n",
            "loss: 3.526523  [ 5500/ 6486]\n",
            "loss: 3.497764  [ 6000/ 6486]\n",
            "Loss: 3.513910807549235\n",
            "Val Loss: 8.472616920623873\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.161901  [    0/ 6486]\n",
            "loss: 3.609889  [  500/ 6486]\n",
            "loss: 3.619134  [ 1000/ 6486]\n",
            "loss: 3.673643  [ 1500/ 6486]\n",
            "loss: 3.519472  [ 2000/ 6486]\n",
            "loss: 3.517243  [ 2500/ 6486]\n",
            "loss: 3.534236  [ 3000/ 6486]\n",
            "loss: 3.527424  [ 3500/ 6486]\n",
            "loss: 3.517782  [ 4000/ 6486]\n",
            "loss: 3.557544  [ 4500/ 6486]\n",
            "loss: 3.550467  [ 5000/ 6486]\n",
            "loss: 3.549665  [ 5500/ 6486]\n",
            "loss: 3.516975  [ 6000/ 6486]\n",
            "Loss: 3.4920515350985184\n",
            "Val Loss: 7.904206496447765\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 1.781613  [    0/ 6486]\n",
            "loss: 3.730326  [  500/ 6486]\n",
            "loss: 4.171107  [ 1000/ 6486]\n",
            "loss: 3.872609  [ 1500/ 6486]\n",
            "loss: 3.702674  [ 2000/ 6486]\n",
            "loss: 3.607004  [ 2500/ 6486]\n",
            "loss: 3.579806  [ 3000/ 6486]\n",
            "loss: 3.604824  [ 3500/ 6486]\n",
            "loss: 3.565337  [ 4000/ 6486]\n",
            "loss: 3.533562  [ 4500/ 6486]\n",
            "loss: 3.564907  [ 5000/ 6486]\n",
            "loss: 3.547582  [ 5500/ 6486]\n",
            "loss: 3.532620  [ 6000/ 6486]\n",
            "Loss: 3.546564907539812\n",
            "Val Loss: 8.022504326451589\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.111870  [    0/ 6486]\n",
            "loss: 3.078786  [  500/ 6486]\n",
            "loss: 3.536661  [ 1000/ 6486]\n",
            "loss: 3.467435  [ 1500/ 6486]\n",
            "loss: 3.677475  [ 2000/ 6486]\n",
            "loss: 3.640878  [ 2500/ 6486]\n",
            "loss: 3.631591  [ 3000/ 6486]\n",
            "loss: 3.635954  [ 3500/ 6486]\n",
            "loss: 3.560516  [ 4000/ 6486]\n",
            "loss: 3.501502  [ 4500/ 6486]\n",
            "loss: 3.483564  [ 5000/ 6486]\n",
            "loss: 3.401070  [ 5500/ 6486]\n",
            "loss: 3.415639  [ 6000/ 6486]\n",
            "Loss: 3.4228393924527314\n",
            "Val Loss: 8.761477737003947\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.281267  [    0/ 6486]\n",
            "loss: 2.903372  [  500/ 6486]\n",
            "loss: 3.226695  [ 1000/ 6486]\n",
            "loss: 3.401041  [ 1500/ 6486]\n",
            "loss: 3.348534  [ 2000/ 6486]\n",
            "loss: 3.360674  [ 2500/ 6486]\n",
            "loss: 3.339031  [ 3000/ 6486]\n",
            "loss: 3.255995  [ 3500/ 6486]\n",
            "loss: 3.278355  [ 4000/ 6486]\n",
            "loss: 3.280627  [ 4500/ 6486]\n",
            "loss: 3.365799  [ 5000/ 6486]\n",
            "loss: 3.380055  [ 5500/ 6486]\n",
            "loss: 3.420456  [ 6000/ 6486]\n",
            "Loss: 3.440841738229329\n",
            "Val Loss: 8.20026757799346\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 35.363880  [    0/ 6486]\n",
            "loss: 3.186233  [  500/ 6486]\n",
            "loss: 3.417897  [ 1000/ 6486]\n",
            "loss: 3.370929  [ 1500/ 6486]\n",
            "loss: 3.408500  [ 2000/ 6486]\n",
            "loss: 3.506466  [ 2500/ 6486]\n",
            "loss: 3.469782  [ 3000/ 6486]\n",
            "loss: 3.448122  [ 3500/ 6486]\n",
            "loss: 3.427333  [ 4000/ 6486]\n",
            "loss: 3.438991  [ 4500/ 6486]\n",
            "loss: 3.529735  [ 5000/ 6486]\n",
            "loss: 3.529945  [ 5500/ 6486]\n",
            "loss: 3.467090  [ 6000/ 6486]\n",
            "Loss: 3.4804829683708243\n",
            "Val Loss: 8.62174553178214\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.069338  [    0/ 6486]\n",
            "loss: 3.108759  [  500/ 6486]\n",
            "loss: 3.242343  [ 1000/ 6486]\n",
            "loss: 3.611365  [ 1500/ 6486]\n",
            "loss: 3.623717  [ 2000/ 6486]\n",
            "loss: 3.674957  [ 2500/ 6486]\n",
            "loss: 3.711832  [ 3000/ 6486]\n",
            "loss: 3.663903  [ 3500/ 6486]\n",
            "loss: 3.553457  [ 4000/ 6486]\n",
            "loss: 3.494244  [ 4500/ 6486]\n",
            "loss: 3.437180  [ 5000/ 6486]\n",
            "loss: 3.412070  [ 5500/ 6486]\n",
            "loss: 3.407608  [ 6000/ 6486]\n",
            "Loss: 3.4395899326054367\n",
            "Val Loss: 9.175587861995979\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.501179  [    0/ 6486]\n",
            "loss: 4.064854  [  500/ 6486]\n",
            "loss: 3.874894  [ 1000/ 6486]\n",
            "loss: 3.843147  [ 1500/ 6486]\n",
            "loss: 3.766747  [ 2000/ 6486]\n",
            "loss: 3.760179  [ 2500/ 6486]\n",
            "loss: 3.642119  [ 3000/ 6486]\n",
            "loss: 3.623272  [ 3500/ 6486]\n",
            "loss: 3.608605  [ 4000/ 6486]\n",
            "loss: 3.549849  [ 4500/ 6486]\n",
            "loss: 3.578928  [ 5000/ 6486]\n",
            "loss: 3.555913  [ 5500/ 6486]\n",
            "loss: 3.502200  [ 6000/ 6486]\n",
            "Loss: 3.431817021188624\n",
            "Val Loss: 7.338063183676433\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 3.978483  [    0/ 6486]\n",
            "loss: 2.957018  [  500/ 6486]\n",
            "loss: 2.986568  [ 1000/ 6486]\n",
            "loss: 3.191737  [ 1500/ 6486]\n",
            "loss: 3.310301  [ 2000/ 6486]\n",
            "loss: 3.210177  [ 2500/ 6486]\n",
            "loss: 3.271311  [ 3000/ 6486]\n",
            "loss: 3.313309  [ 3500/ 6486]\n",
            "loss: 3.347479  [ 4000/ 6486]\n",
            "loss: 3.430551  [ 4500/ 6486]\n",
            "loss: 3.504483  [ 5000/ 6486]\n",
            "loss: 3.520554  [ 5500/ 6486]\n",
            "loss: 3.523964  [ 6000/ 6486]\n",
            "Loss: 3.493735856093248\n",
            "Val Loss: 7.472814525876727\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.281490  [    0/ 6486]\n",
            "loss: 3.074263  [  500/ 6486]\n"
          ]
        }
      ],
      "source": [
        "#epochs = 50\n",
        "t = epoch\n",
        "#for t in range(epochs):\n",
        "while True:#datetime.now().hour < 23:#11\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    t += 1\n",
        "    with open('outfile', 'wb') as fp:\n",
        "        pickle.dump(losses_train, fp)\n",
        "    torch.save({'epoch': t,'model_state_dict': model.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'loss': losses_train[-1],}, \"model_latest\")\n",
        "    \n",
        "    val_loss = test(val_dataloader, model, loss_fn)\n",
        "    print(\"Val Loss:\", val_loss)\n",
        "    if val_loss < min(losses_val):\n",
        "        torch.save({'epoch': t,'model_state_dict': model.state_dict(),'optimizer_state_dict': optimizer.state_dict(),'loss': losses_train[-1],}, \"model_best\")\n",
        "        print(\"Best!\")\n",
        "    losses_val.append(val_loss)\n",
        "    with open('outfile_val', 'wb') as fp:\n",
        "        pickle.dump(losses_val, fp)\n",
        "        \n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Fh-dL01N9y4H",
        "outputId": "d85d1133-9e2d-4b48-eee9-a9511894eb01"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(losses_train)\n",
        "plt.title(\"Training Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(losses_val)\n",
        "plt.title(\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_all(dataloader, model, loss_fn, mask_header = False, inv_mask_header = False, mask_screenshot = False, inv_mask_screenshot = False,\n",
        "             max_price = False, min_price = False, median_price = False, max_year = False, min_year = False, median_year = False,\n",
        "             mask_day = False, inv_mask_day = False, mask_month = False, inv_mask_month = False, mask_genre = False, inv_mask_genre = False,):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    batch_loss = []\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for batch, (X, header, screenshot, y) in enumerate(dataloader):\n",
        "            X, header, screenshot, y = X.to(device), header.to(device), screenshot.to(device), y.to(device)\n",
        "            if inv_mask_header:\n",
        "                mask_screenshot = True\n",
        "                median_price = True\n",
        "                median_year = True\n",
        "                mask_day = True\n",
        "                mask_month = True\n",
        "                mask_genre = True\n",
        "            if inv_mask_screenshot:\n",
        "                mask_header = True\n",
        "                median_price = True\n",
        "                median_year = True\n",
        "                mask_day = True\n",
        "                mask_month = True\n",
        "                mask_genre = True\n",
        "            if inv_mask_day:\n",
        "                mask_header = True\n",
        "                mask_screenshot = True\n",
        "                median_price = True\n",
        "                median_year = True\n",
        "                mask_month = True\n",
        "                mask_genre = True\n",
        "            if inv_mask_month:\n",
        "                mask_header = True\n",
        "                mask_screenshot = True\n",
        "                median_price = True\n",
        "                median_year = True\n",
        "                mask_day = True\n",
        "                mask_genre = True\n",
        "            if inv_mask_genre:\n",
        "                mask_header = True\n",
        "                mask_screenshot = True\n",
        "                median_price = True\n",
        "                median_year = True\n",
        "                mask_day = True\n",
        "                mask_month = True\n",
        "            if mask_header:\n",
        "                header = torch.zeros_like(header)\n",
        "            if mask_screenshot:\n",
        "                screenshot = torch.zeros_like(header)\n",
        "            if max_price:\n",
        "                X[:,0] = 78.99\n",
        "            if median_price:\n",
        "                X[:,0] = 4.79\n",
        "            if min_price:\n",
        "                X[:,0] = 0\n",
        "            if max_year:\n",
        "                X[:,1] = 2019\n",
        "            if median_year:\n",
        "                X[:,1] = 2016\n",
        "            if min_year:\n",
        "                X[:,1] = 1997\n",
        "            if mask_month:\n",
        "                X[:,2:2+12] = 0\n",
        "            if mask_day:\n",
        "                X[:,14:14+31] = 0\n",
        "            if mask_genre:\n",
        "                X[:,45:] = 0\n",
        "            # Forward Pass\n",
        "            headercnn = header_model(header)\n",
        "            headercnn = normalize(headercnn)\n",
        "            screenshotcnn = screenshot_model(screenshot)\n",
        "            screenshotcnn = normalize(screenshotcnn)\n",
        "            header_features = efficientnet_v2_s._modules['features'](headercnn)\n",
        "            avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "            header_features = avgpool(header_features)\n",
        "            screenshot_features = efficientnet_v2_s._modules['features'](screenshotcnn)\n",
        "            screenshot_features = avgpool(screenshot_features)\n",
        "            avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "            header_features = torch.squeeze(torch.squeeze(header_features, 2), 2)\n",
        "            screenshot_features = torch.squeeze(torch.squeeze(screenshot_features, 2), 2)\n",
        "            input = torch.cat((X,header_features,screenshot_features),1)\n",
        "            #print(input.shape)\n",
        "            pred = model(input).to(device)\n",
        "            preds.append(pred)\n",
        "            #y=y.float()\n",
        "            #loss = loss_fn(pred, y)\n",
        "            \n",
        "            #loss, current = loss.item(), batch * len(X)\n",
        "            #batch_loss.append(loss)\n",
        "    all_preds = torch.cat(preds, dim = 0)\n",
        "    epoch_loss = loss_fn(all_preds.to(device), all_ys.to(device))\n",
        "    return all_preds, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "ys = []\n",
        "for batch, (X, header, screenshot, y) in enumerate(test_dataloader):\n",
        "    ys.append(y)\n",
        "all_ys = torch.cat(ys, dim = 0)\n",
        "test_ys = pd.DataFrame(all_ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Test Loss: (tensor([[2.3449, 0.0000],\n",
            "        [2.3449, 0.0000],\n",
            "        [2.3398, 0.0000],\n",
            "        ...,\n",
            "        [2.3371, 0.0000],\n",
            "        [2.3421, 0.0000],\n",
            "        [2.3341, 0.0000]], device='cuda:0'), tensor(20.7233, device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "print(\"Best Test Loss:\", test_all(test_dataloader, model, loss_fn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, mask_header = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, inv_mask_header = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, mask_screenshot = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, inv_mask_screenshot = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, mask_day = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, inv_mask_day = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, mask_month = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, inv_mask_month = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, mask_genre = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, inv_mask_genre = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, max_price = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, median_price = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, min_price = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, max_year = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, median_year = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)\n",
        "preds, epoch_loss = test_all(test_dataloader, model, loss_fn, min_year = True)\n",
        "print(epoch_loss)\n",
        "test_ys = pd.concat([test_ys, pd.DataFrame(preds)], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_ys.astype(float).to_csv(\"test predictions.csv\", encoding='utf-8', index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Main Network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "vscode": {
      "interpreter": {
        "hash": "fc2c6aa7f6d279728ec3a5369e0a1da6c328adf97eab7389969efefe09422e26"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
